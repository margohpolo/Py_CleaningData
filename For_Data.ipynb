{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "import sys,io,os,csv,glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "csv_name = '20180328_eurusd_minute_quote.csv'\n",
    "\n",
    "\n",
    "def process_csv(csv_name):\n",
    "    data = pd.read_csv(csv_name)    \n",
    "    #get date from original file name\n",
    "    csv_date = str(csv_name[0:4]) + str('.') + str(csv_name[4:6]) + str('.') + str(csv_name[6:8])    \n",
    "    #columns need to be labelled in order to create dataframes & manipulate\n",
    "    col_Names=[\"MS\", \"B_O\", \"B_H\", \"B_L\", \"B_C\", \"B_V\", \"A_O\", \"A_H\", \"A_L\", \"A_C\", \"A_V\"]\n",
    "    df = pd.read_csv(csv_name,names=col_Names)\n",
    "    df = df.convert_objects(convert_numeric=True)    \n",
    "    #calculations for df['time']\n",
    "    df['min'] = df.apply(lambda row: int((row['MS'] % 3600000)/60000), axis=1)\n",
    "    df['hour'] = df.apply(lambda row: int((row['MS'] // 3600000)), axis=1)    \n",
    "    #using these dataframes to create output table\n",
    "    df.insert(11,'Date', str(csv_date))\n",
    "    df['Time'] = df.apply(lambda row: (str(row[\"hour\"]).zfill(2) + \":\" + str(row[\"min\"]).zfill(2)), axis=1)\n",
    "    df['Open'] = df.apply(lambda row: float((row['B_O'] + row['A_O'])/2), axis=1)\n",
    "    df['High'] = df.apply(lambda row: float((row['B_H'] + row['A_H'])/2), axis=1)\n",
    "    df['Low'] = df.apply(lambda row: float((row['B_L'] + row['A_L'])/2), axis=1)\n",
    "    df['Close'] = df.apply(lambda row: float((row['B_C'] + row['A_C'])/2), axis=1)\n",
    "    df['Volume'] = df.apply(lambda row: float((row['B_V'] + row['A_V'])/2), axis=1)    \n",
    "    #remove headers as they are not needed in MT4\n",
    "    df_new = df.drop([\"MS\", \"B_O\", \"B_H\", \"B_L\", \"B_C\", \"B_V\", \"A_O\", \"A_H\", \"A_L\", \"A_C\", \"A_V\", \"min\", \"hour\"], axis=1)    \n",
    "    #define filename\n",
    "    csv_newname = str(csv_name[0:8]) + str(\".csv\")\n",
    "    csv_newname    \n",
    "    #save new file\n",
    "    df_new.to_csv(csv_newname, encoding='utf-8', header=False, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next step is to process all the files\n",
    "#unfortunately I didn't have enough hardware powerful enough to run all at once\n",
    "#solution was to run in batches, so I created the next 2 cells\n",
    "#How to Run:\n",
    "#Step 1: Run the above cell\n",
    "#Step 2: Manually copy and paste file names into the 2 cells below\n",
    "#Step 3: Run the cells one at a time\n",
    "#Step 4: Repeat Steps 2 & 3 till done with all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_name = '20180301_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180302_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180304_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180305_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180306_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180307_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180308_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180309_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180311_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180312_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180313_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180314_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180315_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = '20180316_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180318_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180319_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180320_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180321_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180322_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180323_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180325_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180326_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180327_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n",
    "  \n",
    "csv_name = '20180328_eurusd_minute_quote.csv'\n",
    "process_csv(csv_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough Workings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_name = '20050810_eurusd_minute_quote.csv'\n",
    "#process_csv(csv_name)\n",
    "#only run up to 21 at a time; by half month easier to split cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys,io,os,csv,glob\n",
    "#import pandas as pd\n",
    "#from pandas import DataFrame as df\n",
    "\n",
    "#files = str('csv_name = ') + [glob.glob(\"*.csv\")] + str(' process_csv(csv_name)')\n",
    "\n",
    "#data = pd.read_csv('AA_Blank.csv')\n",
    "\n",
    "#df = pd.read_csv('AA_Blank.csv')\n",
    "#df = df.convert_objects(convert_numeric=True, copy=True)\n",
    "\n",
    "#files = [glob.glob(\"*.csv\")]\n",
    "\n",
    "#df['files'] = pd.DataFrame.from_items(files)\n",
    "\n",
    "#stm = str('csv_name = ')\n",
    "\n",
    "#runnn = str(' process_csv(csv_name)')\n",
    "\n",
    "\n",
    "#df.insert(0,'Files', str[glob.glob(\"*.csv\")])\n",
    "\n",
    "#df['files'] = df.apply(lambda row: (str(stm) + files + str(runnn)), axis=1)\n",
    "\n",
    "#df = pd.DataFrame(files)\n",
    "#df.T\n",
    "#df.insert(0,'stm', stm)\n",
    "#df.insert(2,'runnn', runnn)\n",
    "#df.T\n",
    "\n",
    "\n",
    "#df.T.to_csv('AB_Test.csv', encoding='utf-8', header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys,io,os,csv,glob\n",
    "#import pandas as pd\n",
    "#from pandas import DataFrame as df\n",
    "\n",
    "#col_Names=[\"files\"]\n",
    "#df = pd.read_csv('AB_Test.csv',names=col_Names)\n",
    "\n",
    "#stm = str('csv_name = ')\n",
    "\n",
    "#runnn = str(\"\"\"\"\"\"\"\\n\" + ' process_csv(csv_name)' + \"\\n\"\"\"\"\"\"\")\n",
    "\n",
    "#df.insert(0,'stm', stm)\n",
    "#df.insert(2,'runnn', runnn)\n",
    "\n",
    "#df['Total'] = df.apply(lambda row: (str(row[\"stm\"]) + str(row[\"files\"])+ str(row[\"runnn\"])), axis=1)\n",
    "#df.to_csv('AC_DSEE.csv', sep='\\t', encoding='utf-8', header=False, index=False)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#col_Names=[\"stm\",\"files\", \"runnn\", \"Total\"]\n",
    "#df = pd.read_csv('AC_DSEE.csv',names=col_Names)\n",
    "#df = df.convert_objects(convert_numeric=True, copy=True)\n",
    "#print(df.Total)\n",
    "#df.Total.to_csv('Fourth_Try.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
